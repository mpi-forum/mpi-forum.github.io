<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-one-side/one-side-2-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi4-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi41-report-html.idx -basedef mpi4defs.txt -o mpi41-report.tex mpi-report.tex 
-->
<title>Introduction</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h1><span id="Node307">13.1. Introduction</span></h1>
<a href="node306.htm#Node306"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node306.htm#Node306"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node308.htm#Node308"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node306.htm#Node306"> One-Sided Communications</a>
<b>Next: </b><a href="node308.htm#Node308"> Initialization</a>
<b>Previous: </b><a href="node306.htm#Node306"> One-Sided Communications</a>
<p>
<b> Remote Memory Access</b>  
<b> (</b><font face="sans-serif"> RMA</font>)</b>  
extends the communication mechanisms of <font face="sans-serif"> MPI</font> by  
allowing one <font face="sans-serif"> MPI</font> process to specify all communication parameters, both for  
the sending side and for the receiving side.  
This mode of communication facilitates the coding of some applications  
with dynamically changing data access patterns  
where the data distribution is fixed or slowly changing.    
In such a case,  
each <font face="sans-serif"> MPI</font> process can compute what data it needs to access or   
to update at  
other <font face="sans-serif"> MPI</font> processes.    
However, the  
programmer may not be able to easily determine which data in an <font face="sans-serif"> MPI</font> process  
may need to be accessed or to be updated by operations initiated by a  
different <font face="sans-serif"> MPI</font> process, and may not even know which <font face="sans-serif"> MPI</font> processes may perform  
such updates.  
Thus, the transfer parameters are all available only on one side.  
Regular send/receive communication requires matching operations by  
sender and receiver.  
In order to issue the matching operations, an application needs to  
distribute the transfer parameters.   
This distribution may  
require all <font face="sans-serif"> MPI</font> processes to participate in a time-consuming global  
computation,  
or to poll for potential communication requests to  
receive and upon which to act periodically.  
The use of <font face="sans-serif"> RMA</font> communication operations avoids the need for  
global computations or explicit polling.  
A generic example of this nature is the execution of an assignment of  
the form  
<tt>A = B(map)</tt>, where <tt>map</tt> is a permutation vector, and <tt>A</tt>,  
<tt>B</tt>, and <tt>map</tt> are distributed  
in the same manner.    
<P> 
Message-passing communication achieves two effects:  
<em> communication</em> of data from sender to  
receiver and   
<em> synchronization</em> of sender   
with receiver.  
The <font face="sans-serif"> RMA</font> design separates these two functions.  
The following communication calls are provided:  
<ul> 
 
<li>Remote write: <font face="sans-serif"> MPI_PUT</font>, <font face="sans-serif"> MPI_RPUT</font>  
 
<li>Remote read: <font face="sans-serif"> MPI_GET</font>, <font face="sans-serif"> MPI_RGET</font>  
 
<li>Remote update: <font face="sans-serif"> MPI_ACCUMULATE</font>, <font face="sans-serif"> MPI_RACCUMULATE</font>  
 
<li>Remote read and update: <font face="sans-serif"> MPI_GET_ACCUMULATE</font>, <font face="sans-serif"> MPI_RGET_ACCUMULATE</font>,  
and <font face="sans-serif"> MPI_FETCH_AND_OP</font>  
 
<li>Remote atomic swap: <font face="sans-serif"> MPI_COMPARE_AND_SWAP</font>  
</ul> 
<br> 
This chapter refers to an operations set that includes all remote update,  
remote read and update, and remote atomic swap operations as  
``accumulate'' operations.  
<P> 
<font face="sans-serif"> MPI</font> supports two fundamentally different <em> memory models</em>:  
<em> separate</em>  
and <em> unified</em>.  
The separate model makes no assumption about memory consistency and is  
highly portable. This model is similar to that of weakly coherent memory  
systems: the user must impose correct ordering of memory accesses  
through synchronization calls. The  
unified model can exploit cache-coherent hardware and  
hardware-accelerated, one-sided operations that are commonly available  
in high-performance systems.  
The two different models are discussed in detail in  
Section <a href="node326.htm#Node326">Memory Model</a>.  
Both models support several synchronization calls to support  
different synchronization styles.  
<P> 
The design of the <font face="sans-serif"> RMA</font> functions allows implementors to take   
advantage of fast or asynchronous communication mechanisms provided by various  
platforms, such as coherent or noncoherent shared memory, DMA  
engines, hardware-supported put/get operations, and communication  
coprocessors.  The most frequently used <font face="sans-serif"> RMA</font>  
communication mechanisms can be layered on top of message-passing.    
However, certain   
<font face="sans-serif"> RMA</font> functions might need support for asynchronous communication agents in  
software (handlers, threads, etc.) in a distributed memory environment.  
<P> 
We shall denote by <b> origin</b> or <em> origin process</em> the <font face="sans-serif"> MPI</font> process that calls an <font face="sans-serif"> RMA</font> procedure,  
and by <b> target</b> or <em> target process</em> the <font face="sans-serif"> MPI</font> process whose memory is accessed.  
Thus, in a put  
operation, <font face="sans-serif"> source = origin</font> and <font face="sans-serif"> destination = target</font>; in a  
get operation, <font face="sans-serif"> source = target</font> and <font face="sans-serif"> destination = origin</font>.  
<P> 

<P>
<hr>
<a href="node306.htm#Node306"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node306.htm#Node306"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node308.htm#Node308"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node306.htm#Node306"> One-Sided Communications</a>
<b>Next: </b><a href="node308.htm#Node308"> Initialization</a>
<b>Previous: </b><a href="node306.htm#Node306"> One-Sided Communications</a>
<p>
<HR>
Return to <A HREF="node601.htm">MPI-4.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-4.1 of November 2, 2023<BR>
HTML Generated on November 19, 2023
</FONT>
</body>
</html>
