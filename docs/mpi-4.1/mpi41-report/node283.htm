<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-dynamic/dynamic-2-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi4-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi41-report-html.idx -basedef mpi4defs.txt -o mpi41-report.tex mpi-report.tex 
-->
<title>Clarifications</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h2><span id="Node283">12.6.2. Clarifications</span></h2>
<a href="node282.htm#Node282"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node281.htm#Node281"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node284.htm#Node284"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node281.htm#Node281"> <font face="sans-serif"> MPI</font> and Threads</a>
<b>Next: </b><a href="node284.htm#Node284"> The Dynamic Process Model</a>
<b>Previous: </b><a href="node282.htm#Node282"> General</a>
<p>
  
<P> 
<b> Initialization and Completion.</b>  
When using the World Model, the call to <font face="sans-serif"> MPI_FINALIZE</font> should occur on the same thread  
that  
initialized <font face="sans-serif"> MPI</font>. We call this thread the <b> main  
thread</b>.  The call should occur only after all process threads  
have completed their <font face="sans-serif"> MPI</font> calls, and have no <em> pending</em>  
communication or I/O operations.  
 
<br> 
<em> Rationale.</em>  
<P> 
This constraint simplifies implementation.  
 (<em> End of rationale.</em>) <br> 
<b> Threads and the Sessions Model.</b>  
The Sessions Model provides a finer-grain approach to controlling the interaction  
between <font face="sans-serif"> MPI</font> calls and threads.  When using this model,  
the desired level of thread support is specified at Session initialization time.  See Section <a href="node271.htm#Node271">The Sessions Model</a>.  
Thus it is possible for communicators and other <font face="sans-serif"> MPI</font> objects derived from one Session to provide a different level of thread  
support than those created from another Session for which a different level of thread support was requested.  
Depending on the level of thread support requested at Session initialization time, different threads in a <font face="sans-serif"> MPI</font> process can make  
concurrent calls to <font face="sans-serif"> MPI</font> when using <font face="sans-serif"> MPI</font> objects derived from different <em> session handles</em>.  
Note that the requested and provided level of thread support when creating a Session may influence the  
granted level of thread support in a subsequent invocation of <font face="sans-serif"> MPI_SESSION_INIT</font>.  Likewise,  
if the application at some point calls <font face="sans-serif"> MPI_INIT_THREAD</font>, the requested and granted level  
of thread support may influence the granted level of thread support for subsequent calls to <font face="sans-serif"> MPI_SESSION_INIT</font>.  
Similarly, if the application calls <font face="sans-serif"> MPI_INIT_THREAD</font> after a call to <font face="sans-serif"> MPI_SESSION_INIT</font>,  
the level of thread support returned from <font face="sans-serif"> MPI_INIT_THREAD</font> may be similarly influenced by the  
requested level of thread support in the prior call to <font face="sans-serif"> MPI_SESSION_INIT</font>.  
<P> 
In addition, if an <font face="sans-serif"> MPI</font> application is only using the Sessions Model, the provided  
thread support level returned by <font face="sans-serif"> MPI_QUERY_THREAD</font> is the same as that returned prior to invocation of  
<font face="sans-serif"> MPI_INIT_THREAD</font> or <font face="sans-serif"> MPI_INIT</font>.  If the application also used  
the World Model in some component of the application, <font face="sans-serif"> MPI_QUERY_THREAD</font> will  
return the level of thread support returned by the original call to <font face="sans-serif"> MPI_INIT_THREAD</font>.  
<P> 
<b> Multiple threads completing the same request.</b>  
A program in which two threads block, waiting on the same  
request, is erroneous.  Similarly, the same request cannot appear in  
the array of requests of two concurrent  
<font face="sans-serif"> MPI_{WAIT<i>|</i>TEST}{ANY<i>|</i>SOME<i>|</i>ALL}</font>  
calls.  
In <font face="sans-serif"> MPI</font>, a request can only be completed once.  Any combination of  
wait or test that violates this rule is erroneous.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
This restriction is consistent with the view that a multithreaded execution  
corresponds to an interleaving of the <font face="sans-serif"> MPI</font> calls.  
In a single threaded implementation, once a wait is  
posted on a request  
the request handle will be nullified before it is possible to  
post a second wait on the same handle.  
With threads, an <font face="sans-serif"> MPI_WAIT{ANY<i>|</i>SOME<i>|</i>ALL}</font>  
may be blocked without having nullified its request(s) so it  
becomes the user's responsibility to avoid using the same request  
in an <font face="sans-serif"> MPI_WAIT</font> on another thread.  
This constraint also simplifies  
implementation, as only one thread will be blocked on any  
communication or I/O event.  
 (<em> End of rationale.</em>) <br> 
<b> Probe.</b>  
A receive call that uses source and tag values returned by a preceding  
call to <font face="sans-serif"> MPI_PROBE</font> or <font face="sans-serif"> MPI_IPROBE</font> will receive the  
message matched by the probe call only if there was no other matching  
receive  
after the probe and before that receive.  In a multithreaded  
environment, it is up to the user to enforce this condition using  
suitable mutual exclusion logic.  
This can be enforced by  
making sure that each communicator is used by only one thread on each  
process. Alternatively,  
<font face="sans-serif"> MPI_MPROBE</font> or <font face="sans-serif"> MPI_IMPROBE</font> can be used.  
<P> 
<b> Collective calls.</b>  
Matching of collective calls on a  
communicator, window, or file handle is done according to the order in which the calls are issued  
at each process.  If concurrent threads issue such calls on the same  
communicator, window or file handle, it is up to  
the user to make sure the calls are correctly ordered, using  
interthread synchronization.  
 
<br> 
<em> Advice to users.</em>  
<P> 
With three concurrent threads in each <font face="sans-serif"> MPI</font> process of a communicator <font face="sans-serif"> comm</font>,  
  it is allowed that thread A in each <font face="sans-serif"> MPI</font> process calls a collective  
  operation on <font face="sans-serif"> comm</font>, thread B calls a file operation on an existing  
  file handle that was formerly opened on <font face="sans-serif"> comm</font>, and thread C invokes one-sided  
  operations on an existing window handle that was also formerly created  
  on <font face="sans-serif"> comm</font>.  
 (<em> End of advice to users.</em>) <br> 
 
<br> 
<em> Rationale.</em>  
<P> 
As specified in <font face="sans-serif"> MPI_FILE_OPEN</font> and  
  <font face="sans-serif"> MPI_WIN_CREATE</font>, a file handle and  
  a window handle inherit only the group of processes of the underlying  
  communicator, but not the communicator itself. Accesses to communicators,  
  window handles and file handles cannot affect one another.  
 (<em> End of rationale.</em>) <br> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
If the implementation of file or window operations internally  
  uses <font face="sans-serif"> MPI</font> communication then a duplicated communicator may be cached  
  on the file or window object.  
 (<em> End of advice to implementors.</em>) <br> 
<b> Error handlers.</b>  
An error handler does not necessarily execute in the context of the  
thread that made  
the error-raising <font face="sans-serif"> MPI</font> call;  the error handler may be  
executed by a thread that is distinct from the thread that will  
return the error code.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
The <font face="sans-serif"> MPI</font> implementation may be multithreaded, so that part of the  
communication protocol may execute on a thread that is distinct from  
the thread that made the <font face="sans-serif"> MPI</font> call.  
The design allows the error handler to be executed on the  
thread  
where the error is raised.  
 (<em> End of rationale.</em>) <br> 
<b> Interaction with signals and cancellations.</b>  
The outcome is undefined if a thread that executes an <font face="sans-serif"> MPI</font> call is  
cancelled (by another thread), or if a thread catches a signal while  
executing an <font face="sans-serif"> MPI</font> call.  
However, a thread of an <font face="sans-serif"> MPI</font> process may terminate, and may catch  
signals or be cancelled by another thread when not executing <font face="sans-serif"> MPI</font> calls.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
Few C library functions are signal safe, and many have cancellation  
points---points at which the thread executing them may be cancelled.  The  
above restriction simplifies implementation (no need for the <font face="sans-serif"> MPI</font>  
library to be ``async-cancel-safe'' or ``async-signal-safe'').  
 (<em> End of rationale.</em>) <br> 
 
<br> 
<em> Advice to users.</em>  
<P> 
Users can catch signals in separate, non-<font face="sans-serif"> MPI</font> threads (e.g., by  
masking signals on <font face="sans-serif"> MPI</font> calling threads, and unmasking them in one or  
more non-<font face="sans-serif"> MPI</font> threads).  
A good programming practice is to have a distinct thread blocked  
in a call to <tt>sigwait</tt> for each user expected signal that may occur.  
Users must not catch signals used by the <font face="sans-serif"> MPI</font> implementation; as  
each <font face="sans-serif"> MPI</font> implementation is required to document the signals used  
internally, users can avoid these signals.  
 (<em> End of advice to users.</em>) <br> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
The <font face="sans-serif"> MPI</font> library should not invoke  library calls that are  
not thread safe, if multiple threads execute.  
 (<em> End of advice to implementors.</em>) <br> 

<P>
<hr>
<a href="node282.htm#Node282"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node281.htm#Node281"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node284.htm#Node284"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node281.htm#Node281"> <font face="sans-serif"> MPI</font> and Threads</a>
<b>Next: </b><a href="node284.htm#Node284"> The Dynamic Process Model</a>
<b>Previous: </b><a href="node282.htm#Node282"> General</a>
<p>
<HR>
Return to <A HREF="node601.htm">MPI-4.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-4.1 of November 2, 2023<BR>
HTML Generated on November 19, 2023
</FONT>
</body>
</html>
