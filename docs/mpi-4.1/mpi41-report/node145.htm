<!DOCTYPE html>
<html lang=en>
<head>
<!-- This file was generated by tohtml from chap-coll/coll-rendered -->
<!-- with the command
tohtml -default -numbers -dosnl -htables -quietlatex -allgif -endpage mpi4-forum-tail.htm -Wnoredef --mpidoc --latexpgm pdflatex --indexfile mpi41-report-html.idx -basedef mpi4defs.txt -o mpi41-report.tex mpi-report.tex 
-->
<title>Nonblocking Collective Operations</title>
</head>
<body style="background-color:#FFFFFF">
<hr><h1><span id="Node145">7.12. Nonblocking Collective Operations</span></h1>
<a href="node144.htm#Node144"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node113.htm#Node113"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node146.htm#Node146"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node113.htm#Node113"> Collective Communication</a>
<b>Next: </b><a href="node146.htm#Node146"> Nonblocking Barrier Synchronization</a>
<b>Previous: </b><a href="node144.htm#Node144"> Example using <font face="sans-serif"> MPI_SCAN</font></a>
<p>
  
  
As described in Section <a href="node71.htm#Node71">Nonblocking Communication</a>, performance of many  
applications can be improved by overlapping communication and  
computation, and many systems enable this. Nonblocking  
collective operations combine the potential benefits of nonblocking  
point-to-point operations, to exploit overlap and to avoid  
synchronization, with the optimized implementation and message  
scheduling provided by collective  
operations [<a href="node600.htm#-Bib35">35</a>,<a href="node600.htm#-Bib39">39</a>].  One way of  
doing this would be to perform a blocking collective operation in a  
separate thread. An alternative mechanism that often leads to better  
performance (e.g., avoids context switching, scheduler overheads, and  
thread management) is to use nonblocking collective  
communication [<a href="node600.htm#-Bib37">37</a>].  
<P> 
The nonblocking collective communication model is similar to the model   
used for nonblocking point-to-point communication. A nonblocking  
call initiates a collective operation, which must be         
completed in a separate completion call.   
Once initiated, the operation may  
progress  
independently of any  
computation or other communication at participating <font face="sans-serif"> MPI</font> processes. In this  
manner, nonblocking collective operations can mitigate possible  
synchronizing effects of collective operations by running them in the  
``background.''  
In addition to enabling communication-computation  
overlap, nonblocking collective operations can perform  
collective operations on overlapping communicators, which would lead to  
deadlocks with blocking operations. Their semantic advantages can also be  
useful in combination with point-to-point communication.  
<P> 
As in the nonblocking point-to-point case, all calls are local and  
return immediately, irrespective of the status of other <font face="sans-serif"> MPI</font> processes. The  
call initiates the operation, which indicates that the system may  
start to copy data out of the send buffer and into the receive buffer.  
Once initiated, all associated send buffers and buffers associated with  
input arguments (such as arrays of counts, displacements, or datatypes  
in the vector versions of the collectives) should not be modified, and  
all associated receive buffers should not be accessed, until the  
collective operation completes. The  
call returns a request handle, which must be passed to a  
completion call.  
<P> 
All completion calls (e.g., <font face="sans-serif"> MPI_WAIT</font>) described in  
Section <a href="node74.htm#Node74">Communication Completion</a> are supported for nonblocking collective  
operations. Similarly to the blocking case, nonblocking collective operations are  
considered to be complete when the local part of the operation is  
finished, i.e., for the caller, the semantics of the operation are  
guaranteed and all buffers can be safely accessed and modified.  
Completion does not indicate that other <font face="sans-serif"> MPI</font> processes have completed or even  
started the operation (unless otherwise implied by the description of  
the operation). Completion of a particular nonblocking collective  
operation also does not indicate completion of any other posted  
nonblocking collective (or send-receive) operations, whether they are  
posted before or after the completed operation.  
<P> 
 
<br> 
<em> Advice to users.</em>  
<P> 
Users should be aware that implementations are allowed, but not required  
(with exception of <font face="sans-serif"> MPI_IBARRIER</font>), to synchronize <font face="sans-serif"> MPI</font> processes  
during the completion of a nonblocking collective operation.  
 (<em> End of advice to users.</em>) <br> 
Upon returning from a completion call in which a nonblocking collective  
operation completes, the values of  
the <font face="sans-serif"> MPI_SOURCE</font> and <font face="sans-serif"> MPI_TAG</font> fields in the associated status object, if any, are undefined. The  
value of <font face="sans-serif"> MPI_ERROR</font> may be defined, if appropriate, according to  
the specification in Section <a href="node60.htm#Node60">Return Status</a>.  
It is valid to mix different request types (i.e., any combination of  
collective requests, I/O requests, generalized  requests, or  
point-to-point requests) in functions that enable multiple completions  
(e.g., <font face="sans-serif"> MPI_WAITALL</font>).   
It is erroneous to call  
<font face="sans-serif"> MPI_REQUEST_FREE</font> or <font face="sans-serif"> MPI_CANCEL</font> for a request  
associated with a nonblocking collective operation.  
Nonblocking collective requests created using the APIs described in this section are not persistent. However, persistent collective requests can be created using persistent collective operations described in Sections <a href="node159.htm#Node159">Persistent Collective Operations</a> and <a href="node238.htm#Node238">Persistent Neighborhood Communication on Process Topologies</a>.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
Freeing an active nonblocking collective request could cause similar  
problems as discussed for point-to-point requests (see Section <a href="node74.htm#Node74">Communication Completion</a>).  
Cancelling a request is not supported because the semantics of this  
operation are not well-defined.  
 (<em> End of rationale.</em>) <br> 
Multiple nonblocking collective  
operations can be outstanding on a single communicator.   
If the nonblocking call causes some system resource to be exhausted,  
then it will fail and raise an error. Quality implementations  
of <font face="sans-serif"> MPI</font> should ensure that this happens only in pathological cases.  
That is, an <font face="sans-serif"> MPI</font> implementation should be able to support a large number  
of <em> pending</em> nonblocking operations.  
<P> 
Unlike point-to-point operations, nonblocking collective operations do  
not match with blocking collective operations, and collective operations  
do not have a tag argument. All <font face="sans-serif"> MPI</font> processes must call collective  
operations (blocking and nonblocking) in the same order per  
communicator. In particular, once a <font face="sans-serif"> MPI</font> process calls a collective  
operation, all other <font face="sans-serif"> MPI</font> processes in the communicator must eventually  
call the same collective operation, and no other collective operation  
with the same communicator   
in between. This is consistent with the ordering rules for blocking  
collective operations in threaded environments.  
<P> 
 
<br> 
<em> Rationale.</em>  
<P> 
Matching blocking and nonblocking collective operations is not allowed  
because the implementation might use different communication algorithms  
for the two cases. Blocking collective operations may be optimized  
for minimal time to completion, while nonblocking collective operations  
may balance time to completion with CPU overhead and asynchronous  
progress.  
<P> 
The use of tags for collective operations can prevent certain hardware   
optimizations.  
 (<em> End of rationale.</em>) <br> 
 
<br> 
<em> Advice to users.</em>  
<P> 
If program semantics require matching blocking and nonblocking  
collective operations, then a nonblocking collective operation can be  
initiated and immediately completed with a blocking wait to emulate  
blocking behavior.   
 (<em> End of advice to users.</em>) <br> 
In terms of data movement, each nonblocking collective operation has  
the same effect as its blocking counterpart for intra-communicators and  
inter-communicators after completion. Likewise, upon completion,  
nonblocking collective reduction operations have the same effect as  
their blocking counterparts, and the same restrictions and  
recommendations on reduction orders apply.  
<P> 
The use of the ``in place'' option is allowed exactly as described for  
the corresponding blocking collective operations.  When using the ``in  
place'' option, message buffers function as both send and receive  
buffers. Such buffers should not be modified or accessed until the  
operation completes.   
<P> 
The <em> progress</em>  
rules for nonblocking collective operations are similar to  
the progress rules for nonblocking point-to-point operations, refer to  
Sections <a href="node48.htm#Node48">Progress</a> and <a href="node75.htm#Node75">Semantics of Nonblocking Communication Operations</a>.  
<P> 
 
<br> 
<em> Advice  
        to implementors.</em>  
<P> 
Nonblocking collective operations can be implemented with local  
execution schedules [<a href="node600.htm#-Bib38">38</a>] using nonblocking point-to-point  
communication and a reserved tag-space.   
 (<em> End of advice to implementors.</em>) <br> 
<ul> 
</ul> 

<P>
<hr>
<a href="node144.htm#Node144"><img width=16 height=16 src="previous.gif" alt="Previous"></a><a href="node113.htm#Node113"><img width=16 height=16 src="up.gif" alt="Up"></a><a href="node146.htm#Node146"><img width=16 height=16 src="next.gif" alt="Next"></a><br>
<b>Up: </b><a href="node113.htm#Node113"> Collective Communication</a>
<b>Next: </b><a href="node146.htm#Node146"> Nonblocking Barrier Synchronization</a>
<b>Previous: </b><a href="node144.htm#Node144"> Example using <font face="sans-serif"> MPI_SCAN</font></a>
<p>
<HR>
Return to <A HREF="node601.htm">MPI-4.1 Standard Index</A><BR>
Return to <A HREF="http://www.mpi-forum.org/index.html">MPI Forum Home Page</A><BR>
<HR>
<FONT SIZE=-1>(Unofficial) MPI-4.1 of November 2, 2023<BR>
HTML Generated on November 19, 2023
</FONT>
</body>
</html>
